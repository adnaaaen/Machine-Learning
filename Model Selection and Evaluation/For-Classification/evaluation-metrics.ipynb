{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e2de2cd-4f65-4eb9-9b3d-ec6787dd80be",
   "metadata": {},
   "source": [
    "# Model Evaluation Metrics For Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "86d72ac5-649e-45f7-9500-f69b0732c0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Iterable, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fc2a77b-7e85-4116-88f9-5412921992fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_TRUE = [1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0]\n",
    "Y_PRED = [1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225fbef5-b0b6-43b4-bed8-0527b4b0447c",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c515fb-6a92-464d-ba03-b7f4c99e1d29",
   "metadata": {},
   "source": [
    "### FROM SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "afe71645-b3d6-4adb-9cc9-5118027756d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix(y_true: Iterable[int], y_predict: Iterable[int]) -> Iterable[int]:\n",
    "    \"\"\"generate confusion matrix \n",
    "\n",
    "    Args:\n",
    "        y_true (Iterable[int])     : the true prediction values (y_test)\n",
    "        y_predict (Iterabale[int]) : prediction by model (y_pred))\n",
    "\n",
    "    Returns:\n",
    "        Iterale[int] : (TP, TN, FP, FN)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    TP = TN = FP = FN = 0\n",
    "    for y_true, y_pred in zip(y_true, y_predict):\n",
    "        if y_true == 1 and  y_pred == 1:\n",
    "            TP += 1\n",
    "\n",
    "        elif y_true == 1 and y_pred == 0:\n",
    "            FN += 1\n",
    "\n",
    "        elif y_true == 0 and y_pred == 0:\n",
    "            TN += 1\n",
    "\n",
    "        elif y_true == 0 and y_pred == 1:\n",
    "            FP += 1\n",
    "\n",
    "    return TP, TN, FP, FN\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f04eb79f-d40d-4161-87c1-a1e2d576da1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 3, 2, 1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_confusion_matrix(y_true=Y_TRUE, y_predict=Y_PRED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f34b9c-e0dc-4872-8b9c-0cd8754e90f2",
   "metadata": {},
   "source": [
    "### Using Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ee697581-c6f3-41d4-b6f6-9c3bb06cbada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP=np.int64(6), TN=np.int64(3), FP=np.int64(2), FN=np.int64(1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix(Y_TRUE, Y_PRED).ravel()\n",
    "print(f\"{TP=}, {TN=}, {FP=}, {FN=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1418fad4-ad5e-4a85-bcde-30c460152f4b",
   "metadata": {},
   "source": [
    "# Accuracy Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3e6549-51f1-4f5c-a62e-a73ab4500f0d",
   "metadata": {},
   "source": [
    "### FROM SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bcb5ea91-4919-49d2-8f3c-b0b166e1b277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_score(y_true: Iterable[int], y_prediction: Iterable[int]) -> float:\n",
    "    \"\"\"generate accuracy score\n",
    "\n",
    "    Args:\n",
    "        y_true (Iterable[int])     : the true prediction values (y_test)\n",
    "        y_predict (Iterabale[int]) : prediction by model (y_pred))\n",
    "\n",
    "    Returns:\n",
    "        float : accuracy score\n",
    " \n",
    "    \"\"\"\n",
    "    \n",
    "    TP, TN, _, _ = get_confusion_matrix(y_true, y_prediction)\n",
    "    correct_prediction = TP + TN\n",
    "    total_prediction = len(y_prediction)\n",
    "    return (correct_prediction / total_prediction) * 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "351786aa-919d-45f5-9b01-3fd61c1e7caa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy_score(Y_TRUE, Y_PRED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e478fc-661d-4620-b108-02b4aed60f92",
   "metadata": {},
   "source": [
    "### Using Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e892bbe7-6f3f-47bd-9c28-787fe3d3482c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(Y_TRUE, Y_PRED) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc792c9a-ca13-4cf4-8ce1-8916144e4fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c45b648-5bf4-4def-b398-d00a31363c44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
