{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e2de2cd-4f65-4eb9-9b3d-ec6787dd80be",
   "metadata": {},
   "source": [
    "# Model Evaluation Metrics For Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86d72ac5-649e-45f7-9500-f69b0732c0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fc2a77b-7e85-4116-88f9-5412921992fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_TRUE = [1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0]\n",
    "Y_PRED = [1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225fbef5-b0b6-43b4-bed8-0527b4b0447c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c515fb-6a92-464d-ba03-b7f4c99e1d29",
   "metadata": {},
   "source": [
    "### FROM SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afe71645-b3d6-4adb-9cc9-5118027756d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix(\n",
    "    y_true: Iterable[int], y_predict: Iterable[int]\n",
    ") -> Iterable[int]:\n",
    "    \"\"\"generate confusion matrix\n",
    "\n",
    "    Args:\n",
    "        y_true (Iterable[int])     : the true prediction values (y_test)\n",
    "        y_predict (Iterabale[int]) : prediction by model (y_pred))\n",
    "\n",
    "    Returns:\n",
    "        Iterale[int] : (TP, TN, FP, FN)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    TP = TN = FP = FN = 0\n",
    "    for y_true, y_pred in zip(y_true, y_predict):\n",
    "        if y_true == 1 and y_pred == 1:\n",
    "            TP += 1\n",
    "\n",
    "        elif y_true == 1 and y_pred == 0:\n",
    "            FN += 1\n",
    "\n",
    "        elif y_true == 0 and y_pred == 0:\n",
    "            TN += 1\n",
    "\n",
    "        elif y_true == 0 and y_pred == 1:\n",
    "            FP += 1\n",
    "\n",
    "    return TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f04eb79f-d40d-4161-87c1-a1e2d576da1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 3, 2, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_confusion_matrix(y_true=Y_TRUE, y_predict=Y_PRED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f34b9c-e0dc-4872-8b9c-0cd8754e90f2",
   "metadata": {},
   "source": [
    "### Using Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee697581-c6f3-41d4-b6f6-9c3bb06cbada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP=np.int64(6), TN=np.int64(3), FP=np.int64(2), FN=np.int64(1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix(Y_TRUE, Y_PRED).ravel()\n",
    "print(f\"{TP=}, {TN=}, {FP=}, {FN=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1418fad4-ad5e-4a85-bcde-30c460152f4b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Accuracy Score\n",
    "$$\\\\text{Accuracy Score} = \\frac{\\text{Number of Correct Predictions}}{\\text{Number of Predictions}} \\times 100\\$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3e6549-51f1-4f5c-a62e-a73ab4500f0d",
   "metadata": {},
   "source": [
    "### FROM SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcb5ea91-4919-49d2-8f3c-b0b166e1b277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_score(y_true: Iterable[int], y_prediction: Iterable[int]) -> float:\n",
    "    \"\"\"generate accuracy score\n",
    "\n",
    "    Args:\n",
    "        y_true (Iterable[int])     : the true prediction values (y_test)\n",
    "        y_predict (Iterabale[int]) : prediction by model (y_pred))\n",
    "\n",
    "    Returns:\n",
    "        float : accuracy score\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    TP, TN, _, _ = get_confusion_matrix(y_true, y_prediction)\n",
    "    correct_prediction = TP + TN\n",
    "    total_prediction = len(y_prediction)\n",
    "    return (correct_prediction / total_prediction) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "351786aa-919d-45f5-9b01-3fd61c1e7caa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy_score(Y_TRUE, Y_PRED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e478fc-661d-4620-b108-02b4aed60f92",
   "metadata": {},
   "source": [
    "### Using Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e892bbe7-6f3f-47bd-9c28-787fe3d3482c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(Y_TRUE, Y_PRED) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28386060-27f4-4613-9df9-6a036053c069",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Precision Score\n",
    "$$\\\\text{Precision Score} = \\frac{\\text{No.of True Positive}}{\\text{No.of True Positive + No.of False Positive}} \\times 100\\$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f6a924-ecda-479e-a1c2-a70367929bfb",
   "metadata": {},
   "source": [
    "### From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d84f75d-3fa0-4e30-927e-536e560d31d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision_score(y_true: Iterable[int], y_predict: Iterable[int]) -> float:\n",
    "    \"\"\"generate precision score\n",
    "\n",
    "    Args:\n",
    "        y_true (Iterable[int])     : the true prediction values (y_test)\n",
    "        y_predict (Iterabale[int]) : prediction by model (y_pred))\n",
    "\n",
    "    Returns:\n",
    "        float : precesion score\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    TP, _, FP, _ = get_confusion_matrix(Y_TRUE, Y_PRED)\n",
    "    total_positive = TP + FP\n",
    "    return (TP / total_positive) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bba623a5-786b-4f2f-97f2-be87333baf3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_precision_score(Y_TRUE, Y_PRED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde6b368-4614-4f46-a060-4b597ac57586",
   "metadata": {},
   "source": [
    "### Using Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58b38387-5af0-4c8c-af56-49d65368d616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(75.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision_score(Y_TRUE, Y_PRED) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf7675d-2af3-4f58-ba4c-e05f7f4035cf",
   "metadata": {},
   "source": [
    "## Recall Score\n",
    "$$\\\\text{Recall Score} = \\frac{\\text{No.of True Positive}}{\\text{No.of True Positive + No.of False Negative}} \\times 100\\$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d56ad68-eee9-4859-b2af-983b989342ee",
   "metadata": {},
   "source": [
    "### From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83463542-9e43-47d3-9fa8-d8de43bc15ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recall_score(y_true: Iterable[int], y_predict: Iterable[int]) -> float:\n",
    "    \"\"\"generate recall score\n",
    "\n",
    "    Args:\n",
    "        y_true (Iterable[int])     : the true prediction values (y_test)\n",
    "        y_predict (Iterabale[int]) : prediction by model (y_pred))\n",
    "\n",
    "    Returns:\n",
    "        float : recall score\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    TP, _, _, FN = get_confusion_matrix(Y_TRUE, Y_PRED)\n",
    "    total_actual_positive = TP + FN\n",
    "    return (TP / total_actual_positive) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d845167b-b32f-47eb-848c-1cfc7c945a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.71428571428571"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recall_score(Y_TRUE, Y_PRED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6859f2a5-4cc6-4a9f-b397-dd688dd120fd",
   "metadata": {},
   "source": [
    "### Using Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85c20321-503a-4c54-ab1c-a93961ad94ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(85.71428571428571)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "recall_score(Y_TRUE, Y_PRED) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4e6560-ddac-4d48-aa09-def90923c731",
   "metadata": {},
   "source": [
    "## F1 Score\n",
    "$$\\\\text{F1 Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision + Recall}} \\$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba67bfb8-d3c6-4226-b1a8-fffb5bcf7a7e",
   "metadata": {},
   "source": [
    "### From scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac676cda-e2ec-44d5-8923-681626c8d137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score(y_true: Iterable[int], y_predict: Iterable[int]) -> float:\n",
    "    \"\"\"generate f1 score\n",
    "\n",
    "    Args:\n",
    "        y_true (Iterable[int])     : the true prediction values (y_test)\n",
    "        y_predict (Iterabale[int]) : prediction by model (y_pred))\n",
    "\n",
    "    Returns:\n",
    "        float : f1 score\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    recall = get_recall_score(Y_TRUE, Y_PRED)\n",
    "    precision = get_precision_score(Y_TRUE, Y_PRED)\n",
    "    harmonic_mean = 2 * ((recall * precision) / (recall + precision))\n",
    "    return harmonic_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8aa4a5a9-7730-442b-a049-42ef49bc5427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_f1_score(Y_TRUE, Y_PRED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084d8c96-662a-4574-9a72-b5a768d012ab",
   "metadata": {},
   "source": [
    "### Using Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3efafcb-f7f4-41fa-96a2-e9beb318707d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(80.0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(Y_TRUE, Y_PRED) * 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
